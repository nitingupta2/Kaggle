{
    "collab_server" : "",
    "contents" : "\nlibrary(Matrix)\nlibrary(magrittr)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(xgboost)\n\npreProcessFuncName <- \"preProcess7\"\n\nID_VAR <- \"USER_ID\"\nTARGET_VAR <- \"Party\"\n\ngetAUC <- function(y_prob, ylabel) {\n    yhat <- ifelse(y_prob <= 0.5, \"Democrat\", \"Republican\")\n    ModelMetrics::auc(ylabel, as.factor(yhat))\n}\n\ncustom_eval_func <- function (yhat, x_train) {\n    y = getinfo(x_train, \"label\")\n    y_pred = as.integer(yhat > 0.5)\n    err = ModelMetrics::auc(y, y_pred)\n    return (list(metric = \"auc\", value = err))\n}\n\nif(preProcessFuncName == \"preProcess1\") {\n    lParams_xgboost <- list(eta = 0.6,\n                            max_depth = 1,\n                            min_child_weight = 100,\n                            subsample = 1,\n                            colsample_bytree = 0.5,\n                            gamma = 1,\n                            alpha = 1,\n                            best_nrounds = 26,\n                            nthreads = 4\n    )\n} else if(preProcessFuncName == \"preProcess2\") {\n    lParams_xgboost <- list(eta = 0.1,\n                            max_depth = 5,\n                            min_child_weight = 100,\n                            subsample = 0.7,\n                            colsample_bytree = 0.9,\n                            gamma = 1,\n                            alpha = 1,\n                            best_nrounds = 133,\n                            nthreads = 4\n    )\n} else if(preProcessFuncName == \"preProcess3\") {\n    lParams_xgboost <- list(eta = 0.5,\n                            max_depth = 3,\n                            min_child_weight = 100,\n                            subsample = 1.0,\n                            colsample_bytree = 1.0,\n                            gamma = 1,\n                            alpha = 1,\n                            best_nrounds = 32,\n                            nthreads = 4\n    )\n} else if(preProcessFuncName == \"preProcess4\") {\n    lParams_xgboost <- list(eta = 0.1,\n                            max_depth = 4,\n                            min_child_weight = 100,\n                            subsample = 0.7,\n                            colsample_bytree = 1.0,\n                            gamma = 1,\n                            alpha = 1,\n                            best_nrounds = 173,\n                            nthreads = 4\n    )\n} else if(preProcessFuncName == \"preProcess5\") {\n    lParams_xgboost <- list(eta = 0.2,\n                            max_depth = 4,\n                            min_child_weight = 100,\n                            subsample = 0.7,\n                            colsample_bytree = 0.7,\n                            gamma = 1,\n                            alpha = 1,\n                            best_nrounds = 72,\n                            nthreads = 4\n    )\n} else if(preProcessFuncName == \"preProcess6\") {\n    lParams_xgboost <- list(eta = 0.03,\n                            max_depth = 3,\n                            min_child_weight = 100,\n                            subsample = 0.9,\n                            colsample_bytree = 0.5,\n                            gamma = 1,\n                            alpha = 1,\n                            best_nrounds = 357,\n                            nthreads = 4\n    )\n} else if(preProcessFuncName == \"preProcess7\") {\n    lParams_xgboost <- list(eta = 0.4,\n                            max_depth = 1,\n                            min_child_weight = 100,\n                            subsample = 0.9,\n                            colsample_bytree = 0.6,\n                            gamma = 1,\n                            alpha = 1,\n                            best_nrounds = 78,\n                            nthreads = 4\n    )\n}\n\nmodel_xgboost <- function(dfTrain_fold, dfTest_fold, numFolds, seedForFolds) {\n    \n    smm_train_fold <- sparse.model.matrix(Party ~ . -1, data = dfTrain_fold %>% select(-starts_with(ID_VAR)))\n    y_train_fold <- as.integer(as.factor(dfTrain_fold[[TARGET_VAR]])) - 1\n    x_train_fold <- xgb.DMatrix(data = smm_train_fold, label = y_train_fold)\n    \n    smm_test_fold <- sparse.model.matrix(Party ~ . -1, data = dfTest_fold %>% select(-starts_with(ID_VAR)))\n    x_test_fold <- xgb.DMatrix(data = smm_test_fold)\n    \n    smm_test <- sparse.model.matrix(Party ~ . -1, data = dfTest %>% select(-starts_with(ID_VAR)))\n    x_test <- xgb.DMatrix(data = smm_test)\n    \n    set.seed(seedForFolds)\n    xgb_fit <- xgb.train(lParams_xgboost,\n                         x_train_fold,\n                         feval=custom_eval_func,\n                         objective = \"binary:logistic\",\n                         nrounds = as.integer(lParams_xgboost$best_nrounds),\n                         print_every_n = 50)\n    \n    pred_oof <- predict(xgb_fit, x_test_fold)\n    pred_test <- predict(xgb_fit, x_test)\n    \n    return(list(id_oof = dfTest_fold[[ID_VAR]], \n                pred_oof = pred_oof, \n                pred_test = pred_test))\n}\n\n#########################################################################################################################\n\ndfTrain <- read.table(file = paste0(\"train_\", preProcessFuncName, \".tsv\"), header = T, sep = \"\")\ndfTest <- read.table(file = paste0(\"test_\", preProcessFuncName, \".tsv\"), header = T, sep = \"\")\n\nntrain <- nrow(dfTrain)\nntest <- nrow(dfTest)\n\nSEED <- 2016\n\n# Set number of rounds for out of fold predictions\nnumRoundsForFolds <- 5\nnumFolds <- 10\n\n# Set primary seed for generating other seeds\nset.seed(SEED)\n# Generate seeds for creating folds\nvSeeds <- sample(10000, numRoundsForFolds)\n\nlPred_train <- list()\nlPred_test <- list()\n\n# Generate folds for different seeds\nfor(v in seq_along(vSeeds)) {\n    vTrain <- rep(0, ntrain) ; names(vTrain) <- dfTrain[[ID_VAR]]\n    vTest <- rep(0, ntest) ; names(vTest) <- dfTest[[ID_VAR]]\n    vTestIDs <- as.character(dfTest[[ID_VAR]])\n    \n    # Generate folds for cross-validation\n    seedForFolds <- vSeeds[v]\n    set.seed(seedForFolds)\n    lFolds <- caret::createFolds(dfTrain[[TARGET_VAR]], k = numFolds)\n    \n    print(\"Parameters used:\")\n    print(as.data.frame(lParams_xgboost))\n\n    for(i in 1:numFolds) {\n        print(paste(\"Training\", i, \"of\", numFolds, \"folds using seed\", seedForFolds))\n        idx_test <- lFolds[[i]]\n        dfTest_fold <- dfTrain[idx_test,]\n        dfTrain_fold <- dfTrain[-idx_test,]\n        \n        print(paste(\"Training fold observations:\", nrow(dfTrain_fold)))\n        print(paste(\"Test fold observations:\", nrow(dfTest_fold)))\n        \n        lResults <- model_xgboost(dfTrain_fold, dfTest_fold, numFolds, seedForFolds)\n        \n        vTrainIDs <- as.character(lResults$id_oof)\n        vTrain[vTrainIDs] <- vTrain[vTrainIDs] + lResults$pred_oof\n        vTest[vTestIDs] <- vTest[vTestIDs] + lResults$pred_test\n    }\n    \n    lPred_model <- list(train_prob = vTrain, test_prob = vTest/numFolds)\n    \n    lPred_train[[v]] <- lPred_model$train_prob\n    lPred_test[[v]] <- lPred_model$test_prob\n}\n\ndfPred_train <- do.call(cbind.data.frame, lPred_train)\ndfPred_train <- dfPred_train %>% \n                set_colnames(paste(TARGET_VAR, vSeeds, sep = \"_\")) %>% \n                rownames_to_column(var = ID_VAR) %>% \n                mutate(Party = dfTrain[[TARGET_VAR]])\nwrite.csv(dfPred_train, file = paste0(\"ensemble_xgboost_train_\", preProcessFuncName, \".csv\"), row.names = F, quote = F)\n\ndfPred_test <- do.call(cbind.data.frame, lPred_test)\ndfPred_test <- dfPred_test %>% \n                set_colnames(paste(TARGET_VAR, vSeeds, sep = \"_\")) %>% \n                rownames_to_column(var = ID_VAR)\nwrite.csv(dfPred_test, file = paste0(\"ensemble_xgboost_test_\", preProcessFuncName, \".csv\"), row.names = F, quote = F)\n\n#########################################################################################################################\ndfPred_test$Party_prob <- rowMeans(dfPred_test[-1])\ndfPred_test <- dfPred_test %>% \n                mutate(PREDICTIONS = ifelse(Party_prob <= 0.5, \"Democrat\", \"Republican\"))\nwrite.csv(dfPred_test[c(ID_VAR, \"PREDICTIONS\")], \n          file = paste0(\"submission_xgboost_avg_\", preProcessFuncName, \".csv\"), row.names = F, quote = F)\n",
    "created" : 1482454859206.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1515677321",
    "id" : "7E885103",
    "lastKnownWriteTime" : 1482910329,
    "last_content_update" : 1482910329312,
    "path" : "C:/Backups/Kaggle/VotersParty/model_xgboost_ensemble.R",
    "project_path" : "model_xgboost_ensemble.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}